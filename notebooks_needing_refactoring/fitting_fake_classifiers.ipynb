{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ccf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from kyle.sampling.fake_clf import DirichletFC, MultiDirichletFC\n",
    "from kyle.evaluation import (\n",
    "    EvalStats,\n",
    "    compute_accuracy,\n",
    "    compute_ECE,\n",
    "    compute_expected_max,\n",
    ")\n",
    "from kyle.transformations import *\n",
    "from kyle.calibration.calibration_methods import TemperatureScaling\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78eb40",
   "metadata": {},
   "source": [
    "# Realistic Fake Classifiers\n",
    "\n",
    "It's good to have a model of what a realistic Fake Classifier should look like.\n",
    "\n",
    "Probably the simplest model for the fake classifier confidence vector distribution is the **Dirichlet Fake Classifier**:\n",
    "\n",
    "\\begin{equation}\n",
    "C \\sim Dirichlet(\\alpha_1, \\alpha_2, \\alpha_3, ...)\n",
    "\\end{equation}\n",
    "\n",
    "This classifier has a total of 'num_classes' parameters\n",
    "\n",
    "However, this model is possibly a bit too simple as it only has a single local maximum in the distribution. A realistic fake classifier might for example have multiple local maxima in each of the corners of the simplex, i.e. it generally is very confident in its prediction and only very rarely uncertain (center of simplex). Something similar can actually be achieved using the Dirichlet distribution by setting all the parameters $\\alpha_n < 1$. This pushes the distribution out into the corners, BUT however also out onto the sides of the simplex, which is not quite what we want. The center of a side of the simplex corresponds to a confidence vector $\\vec\\alpha = (1/\\text{num_classes}-1, 1/\\text{num_classes}-1, ..., 1/\\text{num_classes}-1, 0)$, i.e. very uncertain in all but one of the classes.\n",
    "\n",
    "Therefore we also consider two other Fake Classifiers that can have multiple local maxima, one in each of the corners, and therefore possibly represent real neural networks better:\n",
    "\n",
    "Firstly the **Multi-Dirichlet Fake Classifier**:\n",
    "\n",
    "\\begin{align}\n",
    "K & \\sim Catgeorical(p_1, p_2, p_3, ...) \\\\\n",
    "C & \\sim Dirichlet_k(\\sigma_k\\cdot[1, 1, ..., 1, \\alpha_k, 1, ...])\n",
    "\\end{align}\n",
    "\n",
    "This classifier has a total of '3 x num_classes' parameters\n",
    "\n",
    "i.e. we first draw from a K-categorical distribution and based on the result we then draw from one of K Dirichlet distributions. Each of the K Dirichlet distributions has two parameters $\\sigma$ and $\\alpha_k$ which represent the width and position of the local maximum in the k-th corner of the simplex.\n",
    "\n",
    "Note: The pdf of this mixture distribution will be a weighted sum of the individual dirichlet distributions\n",
    "\n",
    "Secondly the **Multi-Gaussian Fake Classifier**:\n",
    "\n",
    "K-Categorical followed by one of K Gaussians followed by softmax\n",
    "\n",
    "(probably doesn't make too much sense as Multi-Gaussian pdf is analytically intractable due to the softmax transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854471a8",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "When talking about the simple dirichlet FC $\\vec{\\alpha}$ refers to the vector of $\\alpha$ parameters of the dirichlet distribution.\n",
    "\n",
    "When talking about the Multi-Dirichlet FC $\\vec{\\alpha_k}$ refers to the vector of $\\alpha_k$ parameters, and should not be confused to be a parameter vector of a single dirichlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05413ca4",
   "metadata": {},
   "source": [
    "In order to get an actually realistic Fake Classifier we use these three Fake Classifier models and fit their distributions to the observed confidence vector distributions for a couple of different neural networks.\n",
    "\n",
    "In this case we use:\n",
    "\n",
    "**LeNet 5** on CIFAR 10\n",
    "\n",
    "**ResNet 20** on CIFAR 10\n",
    "\n",
    "**ResNet 110** on CIFAR 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7881576",
   "metadata": {},
   "source": [
    "## Preparing Data and Neural Networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606847e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cifar dataset\n",
    "# normalizarion also from https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "cifar_train_set = datasets.CIFAR10(\n",
    "    os.getcwd(),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
    ")\n",
    "cifar_test_set = datasets.CIFAR10(\n",
    "    os.getcwd(),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), normalize]),\n",
    ")\n",
    "\n",
    "cifar_train = torch.utils.data.DataLoader(\n",
    "    cifar_train_set, batch_size=4, shuffle=True, num_workers=1\n",
    ")\n",
    "cifar_test = torch.utils.data.DataLoader(\n",
    "    cifar_test_set, batch_size=4, shuffle=False, num_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small simple LeNet5 for CIFAR 10 classification\n",
    "\n",
    "\n",
    "class lenet5(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        output = self(x)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        output = self(x)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83698ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proper implementation of ResNet20 for Cifar10. Pytorch only has ResNets for ImageNet which\n",
    "# differ in number of parameters\n",
    "# Code taken from: https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option=\"A\"):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == \"A\":\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(\n",
    "                    lambda x: F.pad(\n",
    "                        x[:, :, ::2, ::2],\n",
    "                        (0, 0, 0, 0, planes // 4, planes // 4),\n",
    "                        \"constant\",\n",
    "                        0,\n",
    "                    )\n",
    "                )\n",
    "            elif option == \"B\":\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(\n",
    "                        in_planes,\n",
    "                        self.expansion * planes,\n",
    "                        kernel_size=1,\n",
    "                        stride=stride,\n",
    "                        bias=False,\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(self.expansion * planes),\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "def resnet32():\n",
    "    return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "def resnet44():\n",
    "    return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "def resnet56():\n",
    "    return ResNet(BasicBlock, [9, 9, 9])\n",
    "\n",
    "\n",
    "def resnet110():\n",
    "    return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "def resnet1202():\n",
    "    return ResNet(BasicBlock, [200, 200, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LeNet5\n",
    "# Load selftrained LeNet 5 and pretrained Resnet20 and Resnet110 (don't have a dedicated GPU at hand D:)\n",
    "# Pretrained nets taken from https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "\n",
    "# selftrained_lenet5 = lenet5()\n",
    "# checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, save_last=True)\n",
    "# trainer = pl.Trainer(max_epochs=20, logger=False, checkpoint_callback=checkpoint_callback)\n",
    "# trainer.fit(selftrained_lenet5, cifar_train, cifar_test)\n",
    "\n",
    "selftrained_lenet5 = lenet5.load_from_checkpoint(\"./trained_models/lenet5.ckpt\")\n",
    "\n",
    "pretrained_resnet20 = resnet20()\n",
    "pretrained_resnet110 = resnet110()\n",
    "\n",
    "pretrained_resnet20_dict = torch.load(\n",
    "    \"./trained_models/resnet20-12fca82f.th\", map_location=torch.device(\"cpu\")\n",
    ")[\"state_dict\"]\n",
    "pretrained_resnet20_dict = {\n",
    "    key.replace(\"module.\", \"\"): value for key, value in pretrained_resnet20_dict.items()\n",
    "}\n",
    "pretrained_resnet20.load_state_dict(pretrained_resnet20_dict)\n",
    "\n",
    "pretrained_resnet110_dict = torch.load(\n",
    "    \"./trained_models/resnet110-1d1ed7c2.th\", map_location=torch.device(\"cpu\")\n",
    ")[\"state_dict\"]\n",
    "pretrained_resnet110_dict = {\n",
    "    key.replace(\"module.\", \"\"): value\n",
    "    for key, value in pretrained_resnet110_dict.items()\n",
    "}\n",
    "pretrained_resnet110.load_state_dict(pretrained_resnet110_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c24ab5",
   "metadata": {},
   "source": [
    "## Set which neural net to use here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00658d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_net = selftrained_lenet5\n",
    "# neural_net = pretrained_resnet20\n",
    "# neural_net = pretrained_resnet110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b46a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NN predictions on CIFAR10 test set\n",
    "cifar_test_full = torch.utils.data.DataLoader(\n",
    "    cifar_test_set, batch_size=len(cifar_test_set), shuffle=False, num_workers=2\n",
    ")\n",
    "images, labels = next(iter(cifar_test_full))\n",
    "\n",
    "neural_net.eval()\n",
    "with torch.no_grad():\n",
    "    logits = neural_net(images)\n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    _, predicted = torch.max(prob, dim=1)\n",
    "    print(f\"NLL = {F.cross_entropy(logits, labels)}\")\n",
    "    print(f\"accuracy = {(predicted == labels).sum().item() / labels.size(0)}\")\n",
    "\n",
    "gt_labels = labels.numpy()\n",
    "confidences = prob.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5992bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels_copy = gt_labels.copy()\n",
    "confidences_copy = confidences.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee930ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = gt_labels_copy.copy()\n",
    "confidences = confidences_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"num non normalized confidence vectors = {np.sum((np.sum(confidences, axis=1) - 1) >= 1e-10)}\"\n",
    ")\n",
    "\n",
    "# confidences are not perfectly normalized due to floating point error\n",
    "# scipy.stats.dirichlet.pdf is very picky about normalization\n",
    "# convert confidences to float64 first for better/more accurate normalization\n",
    "\n",
    "confidences = np.array(confidences, dtype=\"float64\")\n",
    "confidences = confidences / np.sum(confidences, axis=1)[:, None]\n",
    "print(\n",
    "    f\"num non normalized confidence vectors = {np.sum((np.sum(confidences, axis=1) - 1) >= 1e-10)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b77d1",
   "metadata": {},
   "source": [
    "# Fitting Fake Classifiers using MLE\n",
    "\n",
    "**All of this is relatively simple/rudimemtary. 'Proper' Dirichlet fitting would involve something closer to what is described in https://epub.wu.ac.at/4077/1/Report125.pdf.**\n",
    "\n",
    "(Note: Any references to fitted results/distributions/graphs in the following sections used the LeNet5 as the 'real' neural network)\n",
    "\n",
    "Having gotten the confidences of our neural net on the CIFAR 10 test set we can now try and fit an appropiate fake classifier to them. This can be done quite easily for the Dirichlet and Multi-Dirichlet FC's using MLE, as we have relatively simple expressions for the distribution pdf's. The Multi-Gaussian FC is not as easy, as the softmax function complicates the fake classifier's pdf. (It would be necessary to invert the softmax function, which is only possible up to an additive constant. As a result the Multi-Gaussian fake classifier's pdf will be an integral over a gaussian mixture model's pdf.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a40b2b1",
   "metadata": {},
   "source": [
    "## 'Normal' MLE Fitting\n",
    "\n",
    "MLE is probably the easiest and simplest approach when the fake classifier's pdf is known exactly. We calculate the negative log likelihood of our neural net's confidence vector distribution under the assumption of either a Dirichlet or Multi-Dirichlet distribution. Using one of scipy's many minimization algorithms/functions we can then find the set of parameters of the fake classifier that maximize the log-likelihood/minimize the negative log-likelihood.\n",
    "\n",
    "We have introduced this fitting as ``.fit()`` method for the FakeClassifier Classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1618911",
   "metadata": {},
   "source": [
    "Right away we run into a problem, divergences:\n",
    "\n",
    "On the sides and corners of the simplex, when one or many components of the confidence vector are zero, the log-likelihood diverges. If $c_i = 0$ and the corrseponding dirichlet parameter $a_i < 1$ the pdf and the log-likelihood diverge $p(c_i = 0) \\rightarrow + \\infty$. If, however, $a_i > 1$ then $p(c_i)=0$ which will again lead to a divergence in the log-likelihood.\n",
    "\n",
    "Unfortunately a lot of the neural networks are very confident and often predict class confidences near/at $c_i=0$. To mitigate this divergence problem somewhat we can rescale the confidences before fitting according to:\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{c} = \\frac{\\vec{c}(N-1) + 1/\\text{num_classes}}{N}\n",
    "\\end{equation}\n",
    "\n",
    "where N is the number of samples (see https://epub.wu.ac.at/4077/1/Report125.pd). All of the following fits use this rescaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1499c9b",
   "metadata": {},
   "source": [
    "As always with fitting the initial guesses and bounds are important:\n",
    "\n",
    "As discussed at the start a somewhat alright fake classifier can possibly be achieved by using a simple Dirichlet Fake Classifier with alpha parameters $\\alpha_n < 1$. For fitting the DirichletFC appropiate initial guesses and bounds might therefore be $\\vec{\\alpha}_\\text{init} = (1,1,1,1,...)$  and $\\alpha_\\min, \\alpha_\\max = (0.0001, \\text{None})$\n",
    "\n",
    "As dicussed at the start the reasoning behind the Multi-Dirichlet FC is that each separate Dirichlet can be used to create a local maximum in one of the corners of the simplex. This only works if the full alpha vector of each dirichlet has all entries $>1$ (if any entry is $<1$ a local maximum does not exist), which means for each Dirichlet we need $\\alpha_k >1$ and $\\sigma_k>1$. We also expect the maxima to be very 'squished' into the corners. i.e. $\\alpha_k$ to be large. For fitting the Multi-Dirichlet FC appropate initial guesses and bounds might therefore be $\\vec{\\alpha}_{k,\\text{init}} = (10,10,10,10,...)$ $\\vec{\\sigma}_\\text{init} = (2,2,2,2,...)$ and $\\alpha_{k,\\min}, \\alpha_{k,\\max} = (1, \\text{None})$ $\\sigma_\\min, \\sigma_\\max = (1, \\text{None})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4423350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 'EvalStats' and NLL of all the fitted FC's for easier comparison later\n",
    "save_fc_eval = []\n",
    "save_NLL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6331f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Dirichlet FC to the test set confidence vector distributions using MLE fitting\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "Dir_FC = DirichletFC(num_classes)\n",
    "mle_results = Dir_FC.fit(\n",
    "    confidences, initial_alpha=np.ones(num_classes), alpha_bounds=(0.0001, None)\n",
    ")\n",
    "\n",
    "save_NLL.append(mle_results.fun)\n",
    "print(f\"final NLL = {mle_results.fun}\")\n",
    "print(f\"Fitted parameters = {Dir_FC.alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9475c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Multi-Dirichlet FC to the test set confidence vector distributions using MLE fitting\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "mle_results = MultiDir_FC.fit(\n",
    "    confidences,\n",
    "    initial_parameters=np.array([10, 2, 1 / num_classes]),\n",
    "    parameter_bounds=[(1, None), (1, None), (0, 1)],\n",
    "    simplified_fitting=False,\n",
    ")\n",
    "\n",
    "save_NLL.append(mle_results.fun)\n",
    "print(f\"final NLL = {mle_results.fun}\")\n",
    "print(f\"Fitted parameters = {MultiDir_FC.get_parameters()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde0a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visual comparison of neural network and FC distributions\n",
    "Dir_FC_eval = EvalStats(*Dir_FC.get_sample_arrays(50000))\n",
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(25, 25))\n",
    "plt.suptitle(\n",
    "    \"Dirichlet (left) vs Multi-Dirichlet (middle) vs Real NN (right)\", fontsize=25\n",
    ")\n",
    "for i, class_ in enumerate([\"top_class\", 1, 2]):\n",
    "    plt.sca(axs[i, 0])\n",
    "    Dir_FC_eval.plot_confidence_distributions([class_], new_fig=False)\n",
    "    plt.sca(axs[i, 1])\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([class_], new_fig=False)\n",
    "    plt.sca(axs[i, 2])\n",
    "    NNet_eval.plot_confidence_distributions([class_], new_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8dd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(Dir_FC_eval)\n",
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad12c50",
   "metadata": {},
   "source": [
    "Above we have plotted the top class confidence distribution as well as the marginal confidence distributions for the actual neural network and our fitted fake classifiers (the full 10D confidence vector distribution is unfortuanetly a bit difficult to visualise). This allows us to visually inspect how well our fake classifiers really reflect the true confidence distribution of our classifier. The left, middle and right columns correspond to the confidence distributions of the dirichlet fake clsssifier, the multi-dirichlet faske classifier and the real neural network respectively.\n",
    "\n",
    "As expected the simple dirichlet FC does not work well. It doesn't capture the multimodal nature of the true marginal distribution nor the high frequency of p=1.0 confidences in the top class confidence distributions.\n",
    "\n",
    "The Multi-dirichlet FC seems to be a bit better capturing both of these qualities. However the maxima of the distributions don't lie far enough at the extremes, which is likely due to the fact that the local maximum of a dirichlet only lies exactly on the corner in the limit of $\\alpha_k \\rightarrow \\infty$\n",
    "\n",
    "Also of note is that the Multi-Dirichlet FC always tries to fit $\\sigma < 1$, always reaching the lower bound of $\\sigma = 1$ which we have imposed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9cb54",
   "metadata": {},
   "source": [
    "## 'Sufficiently Confident/Class Split' MLE Fitting \n",
    "\n",
    "Given the slight difficulties with fitting a 30 parameter Multi-Dirichlet model we try to simplify the fitting a bit. This can be done by assuming a scenario very similar to that of sufficiently confident fake classifiers. We assume that if we draw a confidence vector from the k'th dirichlet distribution, then that confidence vector always predicts the class k. That means:\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\text{argmax}(\\vec{c}) = k | \\vec{c} \\sim \\text{Dir}_k) \\simeq 1 \\text{  or equivalently  } P(\\text{argmax}(\\vec{c}) = k) \\simeq p_k \n",
    "\\end{equation}\n",
    "\n",
    "where $p_k$ is the weight of the k'th dirichlet distribution. This is of course only a good approximation if $P(\\text{argmax}(\\vec{c}) \\neq k | \\vec{c} \\sim \\text{Dir}_k) \\simeq 0$, i.e. if the individual Dirichlet distributions are sufficiently concentrated in their respective corner of the simplex with only negligible probability mass near the other corners of the simplex.\n",
    "\n",
    "From the marginal class confidence distribution of the real neural network, we can see that this might be a very good approximation, as the class confidences always either lie near $c_k = 1.0$ or $c_k = 0.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d8482",
   "metadata": {},
   "source": [
    "This approximation makes two simplifications possible:\n",
    "\n",
    "1. We no longer have to fit the distribution weights $p_k$. Instead they can simply be read off from the real neural networks predicted class probabilities. This reduces the number of fitted parameters from 30 to 20\n",
    "\n",
    "2. We can now fit each Dirichlet distribution from the Multi-Dirichlet Fake classifier individually to the subset of the data for which $\\text{argmax}(\\vec{c}) = k$. This reduces the problem further from a simultaneous fit of 20 parameters to 10 fits of 2 parameters each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac25abe",
   "metadata": {},
   "source": [
    "We proceed in the following way: First we split the real neural networks confidence distribution by predicted class into 10 subsets. Using the relative size of these subest we estimate the distribution weights of the dirichlet distributions in our Multi-Dirichlet FC. We then fit each dirichlet distribution of our Multi-Dirichlet FC separately to its corresponding data set, by minimizing the negative log likelihood as before.\n",
    "\n",
    "This simplified fitting procedure can be called using ``.fit(..., simplified_fitting=True)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbe734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Multi-Dirichlet FC to the test set confidence vector distributions using above simplification\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "mle_results = MultiDir_FC.fit(\n",
    "    confidences,\n",
    "    initial_parameters=np.array([10, 2]),\n",
    "    parameter_bounds=[(1, None), (1, None)],\n",
    "    simplified_fitting=True,\n",
    ")\n",
    "\n",
    "save_NLL.append(np.sum([k_result.fun for k_result in mle_results]))\n",
    "print(f\"final NLL = {np.sum([k_result.fun for k_result in mle_results])}\")\n",
    "print(\n",
    "    \"alpha = {}\\n\\nsigma = {}\\n\\ndistribution_weights = {}\".format(\n",
    "        *MultiDir_FC.get_parameters()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2c84a",
   "metadata": {},
   "source": [
    "Similar to above we can now visiually compare the marginal and top class confidence distributions of our fake classifier and the real neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53399344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "plt.suptitle(\"Simplified Multi-Dirichlet (left) vs Real NN (right)\", fontsize=15)\n",
    "for i, class_ in enumerate([\"top_class\", 1, 2]):\n",
    "    plt.sca(axs[i, 0])\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([class_], new_fig=False)\n",
    "    plt.sca(axs[i, 1])\n",
    "    NNet_eval.plot_confidence_distributions([class_], new_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd8860",
   "metadata": {},
   "source": [
    "This doesn't really seem to work much better than fitting all 30 parameters at the same time. It actually looks qualitativley worse. This is likely due to the fact that the approximation made to 'derive' this fitting procedure is simply not very good in the case of LeNet5. However, with ResNet20 and ResNet110 this approximation becomes much better and the 'class split' fitting produces almost exactly the same results.\n",
    "\n",
    "Most importatntly though, it is much less computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654ff88",
   "metadata": {},
   "source": [
    "## Sigma < 1\n",
    "\n",
    "Interestingly enough the simplified fitting runs into the same problem of always trying to fit very small $\\sigma_k < 1$, even though the sensible/intuitve choice would be $\\sigma_k > 1$. This indicates that maybe our sensible/intuitve choice of wanting $\\sigma_k > 1$ isn't actually that sensible. As explained earlier the reasoning behind the Multi-Dirichlet model is that each Dirichlet distribution is used to create a local maximum in one of the corners of the simplex, with $\\alpha_k$ determining how squished into the corner and $\\sigma_k$ how broad the local maximum is. The requirement of $\\sigma_k > 1$ and $\\alpha_k > 1$ arose, because if any parameter of the Dirichlet is $< 1$ a local maximum does not exist and our whole reasoning behind introducing the Multi-Dirichlet fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5050c",
   "metadata": {},
   "source": [
    "However, as it turns out a reasonable parameter choice might also be $\\sigma_k < 1$, with $\\alpha_k \\cdot \\sigma_k > 1$. This would mean that all parameters of the dirichlet, with exception of the k'th entry, are $ < 1$. While a local maximum no longer exists (we now have divergences at the sides and corners) this can still lead to an equivalent situation with most of the probability mass concentrated in one corner of the simplex. Below is a quick and dirty visualisation of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c360ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "vis_dir_FC = DirichletFC(3)\n",
    "\n",
    "vis_dir_FC.set_alpha([0.2, 20, 0.2])\n",
    "_, vis_confidences = vis_dir_FC.get_sample_arrays(10000)\n",
    "\n",
    "ax[0].scatter(vis_confidences[:, 0], vis_confidences[:, 1], s=0.1)\n",
    "ax[0].plot([0, 1], [1, 0], \"r--\")\n",
    "ax[0].plot([0, 1], [0, 0], \"r--\")\n",
    "ax[0].plot([0, 0], [0, 1], \"r--\")\n",
    "ax[0].set_xlim([-0.2, 1.2])\n",
    "ax[0].set_ylim([-0.2, 1.2])\n",
    "\n",
    "vis_dir_FC.set_alpha([2, 50, 2])\n",
    "_, vis_confidences = vis_dir_FC.get_sample_arrays(10000)\n",
    "\n",
    "ax[1].scatter(vis_confidences[:, 0], vis_confidences[:, 1], s=0.1)\n",
    "ax[1].plot([0, 1], [1, 0], \"r--\")\n",
    "ax[1].plot([0, 1], [0, 0], \"r--\")\n",
    "ax[1].plot([0, 0], [0, 1], \"r--\")\n",
    "ax[1].set_xlim([-0.2, 1.2])\n",
    "ax[1].set_ylim([-0.2, 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176821eb",
   "metadata": {},
   "source": [
    "Below we have repeated both the direct Multi-Dirichlet FC fitting as well as the 'class split' fitting, but this time with a lower bound for sigma of $\\sigma_\\text{lower} = 0.001$. Allowing for small $\\sigma$ seems to improve things quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554757d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Multi-Dirichlet FC allowing sigma < 1\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "mle_results = MultiDir_FC.fit(\n",
    "    confidences,\n",
    "    initial_parameters=np.array([10, 2, 1 / num_classes]),\n",
    "    parameter_bounds=[(1, None), (0.001, None), (0, 1)],\n",
    "    simplified_fitting=False,\n",
    ")\n",
    "\n",
    "save_NLL.append(mle_results.fun)\n",
    "print(f\"final NLL = {mle_results.fun}\")\n",
    "print(\n",
    "    \"alpha = {}\\n\\nsigma = {}\\n\\ndistribution_weights = {}\".format(\n",
    "        *MultiDir_FC.get_parameters()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e847a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "plt.suptitle(\"Multi-Dirichlet w/ sigma < 1 (left) vs Real NN (right)\", fontsize=15)\n",
    "for i, class_ in enumerate([\"top_class\", 1, 2]):\n",
    "    plt.sca(axs[i, 0])\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([class_], new_fig=False)\n",
    "    plt.sca(axs[i, 1])\n",
    "    NNet_eval.plot_confidence_distributions([class_], new_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57486d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cde78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Multi-Dirichlet FC allowing sigma < 1 with simplified fitting\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "mle_results = MultiDir_FC.fit(\n",
    "    confidences,\n",
    "    initial_parameters=np.array([10, 2]),\n",
    "    parameter_bounds=[(1, None), (0.001, None)],\n",
    "    simplified_fitting=True,\n",
    ")\n",
    "\n",
    "save_NLL.append(np.sum([k_result.fun for k_result in mle_results]))\n",
    "print(f\"final NLL = {np.sum([k_result.fun for k_result in mle_results])}\")\n",
    "print(\n",
    "    \"alpha = {}\\n\\nsigma = {}\\n\\ndistribution_weights = {}\".format(\n",
    "        *MultiDir_FC.get_parameters()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e783d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))\n",
    "plt.suptitle(\n",
    "    \"Simplified Multi-Dirichlet w/ sigma < 1 (left) vs Real NN (right)\", fontsize=15\n",
    ")\n",
    "for i, class_ in enumerate([\"top_class\", 1, 2]):\n",
    "    plt.sca(axs[i, 0])\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([class_], new_fig=False)\n",
    "    plt.sca(axs[i, 1])\n",
    "    NNet_eval.plot_confidence_distributions([class_], new_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b49390",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6a90a",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The confidence distributions have been aggregated here again for easier comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2674d5a",
   "metadata": {},
   "source": [
    "### Real NN's Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c824e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plt.axes(axs[0])\n",
    "NNet_eval.plot_confidence_distributions([\"top_class\"], new_fig=False)\n",
    "plt.axes(axs[1])\n",
    "NNet_eval.plot_confidence_distributions([0], new_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c88e7c",
   "metadata": {},
   "source": [
    "### Dirichlet FC Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fec3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"final NLL = {save_NLL[0]}\")\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[0].plot_confidence_distributions([\"top_class\"], new_fig=False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[0].plot_confidence_distributions([0], new_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2c2ec",
   "metadata": {},
   "source": [
    "### Directly Fitted Multi Dirichlet FC Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b58dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"final NLL = {save_NLL[1]}\")\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[1].plot_confidence_distributions([\"top_class\"], new_fig=False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[1].plot_confidence_distributions([0], new_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2776ab",
   "metadata": {},
   "source": [
    "### Class Split Fitted Multi Dirichlet FC Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"final NLL = {save_NLL[2]}\")\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[2].plot_confidence_distributions([\"top_class\"], new_fig=False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[2].plot_confidence_distributions([0], new_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d6c0f",
   "metadata": {},
   "source": [
    "### Directly Fitted Multi Dirichlet FC Confidence Distribution, sigma < 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"final NLL = {save_NLL[3]}\")\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[3].plot_confidence_distributions([\"top_class\"], new_fig=False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[3].plot_confidence_distributions([0], new_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728487c5",
   "metadata": {},
   "source": [
    "### Class Split Fitted Multi Dirichlet FC Confidence Distribution, sigma < 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"final NLL = {save_NLL[4]}\")\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[4].plot_confidence_distributions([\"top_class\"], new_fig=False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[4].plot_confidence_distributions([0], new_fig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a665cc1",
   "metadata": {},
   "source": [
    "\n",
    "Comparing how well different models fit is always a bit of a tricky thing to do. The Likelihood ratio test only works for comparing nested models, i.e. models where one is a special/restricted case of the other model, which is unfortunately not the case here.\n",
    "\n",
    "However, non-nested models can be compared (informally) using the Akaike Information Criterion (AIC), defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "AIC = 2k - 2\\ln(\\hat{L})\n",
    "\\end{equation}\n",
    "\n",
    "where $k$ is the number of parameters of the model and $\\hat{L}$ the maximum lilelihood.\n",
    "\n",
    "Given that our models have parameters of either on the order of $\\sim 10^1$ whereas $\\ln(\\hat{L}) \\sim 10^6$ we can pretty much just compare likelihoods directly.\n",
    "\n",
    "### For the LeNet 5 we conclude:\n",
    "\n",
    "1. Suprisingly, the simple Dirichlet fits the real NN better than the Multi-Dirichlet with $\\sigma > 1$, even though visually it looks like the Multi-Dirichlet captures/reproduces the marginal distributions of the real NN a lot better\n",
    "\n",
    "2. Also suprisingly, fitting the Multi-Dirichlet directly gives worse results according to the AIC comared to fitting it via the approximation of 'class splitting' (even though, again, the directly fitted Multi-Dirichlet marginal distributions looks more 'real')\n",
    "\n",
    "3. Allowing for $\\sigma < 1$ improves the AIC a lot for both directly and class split fitted Multi-Dirichlet FC's\n",
    "\n",
    "The 'most real' results seem to be achieved using the directly fitted Multi-Dirichlet FC and allowing sigma < 1. While it does actually result in a slightly worse AIC than the same class-split FC the marginal distributions look a lot more 'real'.\n",
    "\n",
    "### For the ResNet 20 we conclude:\n",
    "\n",
    "Similar results as for the LeNet 5 with one major exception:\n",
    "\n",
    "The difference between the class split and directly fitted multi dirichlet FC is negligibly small. This not a suprise as we expect the more complex NN's to be more confident in general, i.e. for the confidences to be more concentrated in the corners. This makes the more complex NN's closer to a 'sufficiently confident like' behaviour that we based the class split fitting approximation on.\n",
    "\n",
    "Again the most promising results seem to be achieved using the directly fitted Multi-Dirichlet FC and allowing sigma < 1.\n",
    "\n",
    "### For the ResNet 110 we conclude:\n",
    "\n",
    "Pretty much almost the same as for the ResNet 20\n",
    "\n",
    "### In General:\n",
    "\n",
    "The Multi-Dirichlet FC seems to be a lot better at reproducing the ResNet 20 and ResNet 110 confidence distributions. The LeNet 5 is more difficult for the Multi-Dirichlet FC to reproduce. This is likely due to the LeNet 5 not being 'overconfident enough', i.e. when looking at  the LeNet's 'top class' confidence distribution a fair amount of confidences lie in the middle of the distribution at $p \\sim 0.5$. For ResNet 20 and ResNet 110 this is not the case, pretty much all confidences lie at the extreme value of $p \\sim 1.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207568b4",
   "metadata": {},
   "source": [
    "Maybe TODO: Try other fitting methods: e.g. moment matching or fitting only to the marginal distributions\n",
    "\n",
    "Maybe TODO: Try 'stochastic fitting' for the multi-gaussian FC where we sample the FC calculate the corrseponding marginal distributions and minimize e.g. the squared error loss between the neural network marginal distributions and the marginal distributions sampled from the FC. Could get around problem of multi-gaussian FC having analytically intractable pdf\n",
    "\n",
    "TODO: Find a good simplex automorphism to also recreate the reliability diagrams of the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886ed246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14560a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bbf6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "848c1ade",
   "metadata": {},
   "source": [
    "## This didn't really work but it's here for completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076089c",
   "metadata": {},
   "source": [
    "## Further Modifications to Fitting Procedure\n",
    "\n",
    "There are definitely more ways to improve the fitting procedure (see https://epub.wu.ac.at/4077/1/Report125.pdf).\n",
    "\n",
    "A relatively simple one is to transform the parameters before fitting. In general, introducing bounds into minimzation problems can complicate things. However instead of fitting the dirichlet parameters directly we can first rescale/transform them onto the interval $[-\\infty, \\infty]$ (Very similar to the idea of generalized linear models, just that we do not have predictor variables in our case).\n",
    "\n",
    "For the simple dirichlet FC and appropiate rescaling would be $log(\\cdot)$ mapping the allowed alpha interval $[0, \\infty]$ onto $[-\\infty, \\infty]$\n",
    "\n",
    "For the multi-dirichlet FC, with $\\sigma > 0$ and $\\alpha > 1$ an appropiate transform would be e.g. $log(\\sigma)$ and $log(\\alpha - 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416f7fe",
   "metadata": {},
   "source": [
    "Below we fitted the Multi-Dirichlet FC again, using both the direct and 'clas split' fitting procedure, however this time with the above transformstions applied to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629f308",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "As it turns out rescaling the parameters might not be that great of an idea. The problem is that the minimization algorithms end up taking stepsizes of up to $10$ in $\\log(\\alpha)$ which results in $\\alpha \\sim 10^{10}$. Even after rescaling the confidences to avoid 0 values, we still run into problems with such a large alpha. For a value of $c \\sim 10^{-5}$, we get $c^\\alpha \\sim 10^{-50}$ which might as well be 0 and will lead to errors in the log-likelihood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the confidences to avoid 0 confidences and renormalize\n",
    "\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "rescaled_confidences = (\n",
    "    confidences * (confidences.shape[0] - 1) + 1 / num_classes\n",
    ") / confidences.shape[0]\n",
    "rescaled_confidences = (\n",
    "    rescaled_confidences / np.sum(rescaled_confidences, axis=1)[:, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afdb89c",
   "metadata": {},
   "source": [
    "### First the simultaneous fit of 30 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfba92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "\n",
    "\n",
    "def MultiDir_NLL(log_alpha, log_sigma, logit_distribution_weights):\n",
    "    alpha = np.exp(log_alpha) + 1\n",
    "    sigma = np.exp(log_sigma)\n",
    "    distribution_weights = np.exp(logit_distribution_weights) / (\n",
    "        1 + np.exp(logit_distribution_weights)\n",
    "    )\n",
    "    return -np.sum(\n",
    "        np.log(\n",
    "            MultiDir_FC.pdf(rescaled_confidences, alpha, sigma, distribution_weights)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# initial guesses for fitting multi-dirichlet (no longer need bounds due to log transformations)\n",
    "init_log_alpha = np.zeros(num_classes)\n",
    "init_log_sigma = np.zeros(num_classes)\n",
    "init_logit_distribution_weights = np.zeros(num_classes)\n",
    "\n",
    "MultiDirichlet_bestfit = scipy.optimize.minimize(\n",
    "    lambda parms: MultiDir_NLL(*np.split(parms, 3)),\n",
    "    np.concatenate((init_log_alpha, init_log_sigma, init_logit_distribution_weights)),\n",
    "    options={\"disp\": True},\n",
    ")\n",
    "print(f\"final NLL = {MultiDirichlet_bestfit.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set FC parameters to those found from MLE fit\n",
    "l_a, l_s, l_w = np.split(MultiDirichlet_bestfit.x, 3)\n",
    "MultiDir_FC.set_parameters(\n",
    "    np.exp(l_a) + 1, np.exp(l_s), np.exp(l_w) / (1 + np.exp(l_w))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}\".format(\n",
    "        *np.split(MultiDirichlet_bestfit.x, 3)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0, \"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0, \"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4a3e1",
   "metadata": {},
   "source": [
    "### And secondly the 10 fits of 2 parameters each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d405235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_split_confidences = [\n",
    "    rescaled_confidences[np.argmax(rescaled_confidences, axis=1) == i, :]\n",
    "    for i in range(num_classes)\n",
    "]\n",
    "\n",
    "estimated_distribution_weights = [\n",
    "    k_class_confidences.shape[0] for k_class_confidences in class_split_confidences\n",
    "]\n",
    "estimated_distribution_weights = estimated_distribution_weights / np.sum(\n",
    "    estimated_distribution_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad35460",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir_FC = DirichletFC(num_classes)\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "\n",
    "alpha_k = []\n",
    "sigma_k = []\n",
    "NLL_k = []\n",
    "\n",
    "for k, k_class_confidences in enumerate(class_split_confidences):\n",
    "\n",
    "    def k_dir_NLL(log_alpha, log_sigma):\n",
    "        alpha_vector = np.ones(num_classes)\n",
    "        alpha_vector[k] = np.exp(log_alpha) + 1\n",
    "        alpha_vector *= np.exp(log_sigma)\n",
    "        return -np.sum(np.log(Dir_FC.pdf(k_class_confidences, alpha_vector)))\n",
    "\n",
    "    # initial guesses fitting individual dirichlets (no longer need bounds due to log transformations)\n",
    "    init_log_alpha = 0\n",
    "    init_log_sigma = 0\n",
    "\n",
    "    k_dir_bestfit = scipy.optimize.minimize(\n",
    "        lambda parms: k_dir_NLL(*parms),\n",
    "        np.array([init_log_alpha, init_log_sigma]),\n",
    "        options={\"disp\": True},\n",
    "    )\n",
    "\n",
    "    alpha_k.append(np.exp(k_dir_bestfit.x[0]) + 1)\n",
    "    sigma_k.append(np.exp(k_dir_bestfit.x[1]))\n",
    "    NLL_k.append(k_dir_bestfit.fun)\n",
    "\n",
    "print(f\"final NLL = {np.sum(NLL_k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC.set_parameters(alpha_k, sigma_k, estimated_distribution_weights)\n",
    "print(\n",
    "    \"alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}\".format(\n",
    "        *MultiDir_FC.get_parameters()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0, \"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0, \"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
