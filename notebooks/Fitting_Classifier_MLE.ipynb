{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ccf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from kyle.sampling.fake_clf import DirichletFC, MultiDirichletFC\n",
    "from kyle.evaluation import EvalStats, compute_accuracy, compute_ECE, compute_expected_max\n",
    "from kyle.transformations import *\n",
    "from kyle.calibration.calibration_methods import TemperatureScaling\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78eb40",
   "metadata": {},
   "source": [
    "# Realistic Fake Classifiers\n",
    "\n",
    "It's good to have a model of what a realistic Fake Classifier should look like.\n",
    "\n",
    "Probably the simplest model for the fake classifier confidence vector distribution is the **Dirichlet Fake Classifier**:\n",
    "\n",
    "\\begin{equation}\n",
    "C \\sim Dirichlet(\\alpha_1, \\alpha_2, \\alpha_3, ...)\n",
    "\\end{equation}\n",
    "\n",
    "This classifier has a total of 'num_classes' parameters\n",
    "\n",
    "However, this model is possibly a bit too simple as it only has a single local maximum in the distribution. A realistic fake classifier might for example have multiple local maxima in each of the corners of the simplex, i.e. it generally is very confident in its prediction and only very rarely uncertain (center of simplex). Something similar can actually be achieved using the Dirichlet distribution by setting all the parameters $\\alpha_n < 1$. This pushes the distribution out into the corners, BUT however also out onto the sides of the simplex, which is not quite what we want. The center of a side of the simplex corresponds to a confidence vector $\\vec\\alpha = (1/\\text{num_classes}-1, 1/\\text{num_classes}-1, ..., 1/\\text{num_classes}-1, 0)$, i.e. very uncertain in all but one of the classes.\n",
    "\n",
    "Therefore we also consider two other Fake Classifiers that can have multiple local maxima, one in each of the corners, and therefore possibly represent real neural networks better:\n",
    "\n",
    "Firstly the **Multi-Dirichlet Fake Classifier**:\n",
    "\n",
    "\\begin{align}\n",
    "K & \\sim Catgeorical(p_1, p_2, p_3, ...) \\\\\n",
    "C & \\sim Dirichlet_k(\\sigma_k\\cdot[1, 1, ..., 1, \\alpha_k, 1, ...])\n",
    "\\end{align}\n",
    "\n",
    "This classifier has a total of '3 x num_classes' parameters\n",
    "\n",
    "i.e. we first draw from a K-categorical distribution and based on the result we then draw from one of K Dirichlet distributions. Each of the K Dirichlet distributions has two parameters $\\sigma$ and $\\alpha_k$ which represent the width and position of the local maximum in the k-th corner of the simplex.\n",
    "\n",
    "Note: The pdf of this mixture distribution will be a weighted sum of the individual dirichlet distributions\n",
    "\n",
    "Secondly the **Multi-Gaussian Fake Classifier**:\n",
    "\n",
    "K-Categorical followed by one of K Gaussians followed by softmax\n",
    "\n",
    "(probably doesn't make too much sense as Multi-Gaussian pdf is analytically intractable due to the softmax transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854471a8",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "When talking about the simple dirichlet FC $\\vec{\\alpha}$ refers to the vector of $\\alpha$ parameters of the dirichlet distribution.\n",
    "\n",
    "When talking about the Multi-Dirichlet FC $\\vec{\\alpha_k}$ refers to the vector of $\\alpha_k$ parameters, and should not be confused to be a parameter vector of a single dirichlet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05413ca4",
   "metadata": {},
   "source": [
    "In order to get an actually realistic Fake Classifier we use these three Fake Classifier models and fit their distributions to the observed confidence vector distributions for a couple of different neural networks.\n",
    "\n",
    "In this case we use:\n",
    "\n",
    "**LeNet 5** on CIFAR 10\n",
    "\n",
    "**ResNet 20** on CIFAR 10\n",
    "\n",
    "**ResNet 110** on CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606847e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cifar dataset\n",
    "#normalizarion also from https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "cifar_train_set = datasets.CIFAR10(os.getcwd(), train=True, download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "cifar_test_set = datasets.CIFAR10(os.getcwd(), train=False, download=True,\n",
    "                transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "cifar_train = torch.utils.data.DataLoader(cifar_train_set, batch_size=4, shuffle=True, num_workers=2)\n",
    "cifar_test = torch.utils.data.DataLoader(cifar_test_set, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a43d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small simple LeNet5 for CIFAR 10 classification\n",
    "\n",
    "class lenet5(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        output = self(x)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, target = batch\n",
    "        output = self(x)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83698ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proper implementation of ResNet18 for Cifar10. Pytorch only has ResNets for ImageNet which\n",
    "#differ in number of parameters\n",
    "#Code taken from: https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "def resnet32():\n",
    "    return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "def resnet44():\n",
    "    return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "def resnet56():\n",
    "    return ResNet(BasicBlock, [9, 9, 9])\n",
    "\n",
    "\n",
    "def resnet110():\n",
    "    return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "def resnet1202():\n",
    "    return ResNet(BasicBlock, [200, 200, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train a LeNet5\n",
    "#Load selftrained LeNet 5 and pretrained Resnet20 and Resnet110 (don't have a dedicated GPU at hand D:)\n",
    "#Pretrained nets taken from https://github.com/akamaster/pytorch_resnet_cifar10\n",
    "\n",
    "#selftrained_lenet5 = lenet5()\n",
    "#checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, save_last=True)\n",
    "#trainer = pl.Trainer(max_epochs=20, logger=False, checkpoint_callback=checkpoint_callback)\n",
    "#trainer.fit(selftrained_lenet5, cifar_train, cifar_test)\n",
    "\n",
    "selftrained_lenet5 = lenet5.load_from_checkpoint('./trained_models/lenet5.ckpt')\n",
    "\n",
    "pretrained_resnet20 = resnet20()\n",
    "pretrained_resnet110 = resnet110()\n",
    "\n",
    "pretrained_resnet20_dict = torch.load('./trained_models/resnet20-12fca82f.th',\n",
    "                               map_location=torch.device('cpu'))['state_dict']\n",
    "pretrained_resnet20_dict = {key.replace(\"module.\", \"\"): value for key, value in pretrained_resnet20_dict.items()}\n",
    "pretrained_resnet20.load_state_dict(pretrained_resnet20_dict)\n",
    "\n",
    "pretrained_resnet110_dict = torch.load('./trained_models/resnet110-1d1ed7c2.th',\n",
    "                               map_location=torch.device('cpu'))['state_dict']\n",
    "pretrained_resnet110_dict = {key.replace(\"module.\", \"\"): value for key, value in pretrained_resnet110_dict.items()}\n",
    "pretrained_resnet110.load_state_dict(pretrained_resnet110_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c24ab5",
   "metadata": {},
   "source": [
    "**Set which neural net to fit here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00658d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_net = selftrained_lenet5\n",
    "neural_net = pretrained_resnet20\n",
    "#neural_net = pretrained_resnet110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b46a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get NN predictions on CIFAR10 test set\n",
    "\n",
    "cifar_test_full = torch.utils.data.DataLoader(cifar_test_set, batch_size=len(cifar_test_set),\n",
    "                                              shuffle=False, num_workers=2)\n",
    "images, labels = next(iter(cifar_test_full))\n",
    "\n",
    "neural_net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    logits = neural_net(images)\n",
    "    prob = F.softmax(logits, dim=1)\n",
    "    _, predicted = torch.max(prob, dim=1)\n",
    "    print(f'NLL = {F.cross_entropy(logits, labels)}')\n",
    "    print(f'accuracy = {(predicted == labels).sum().item() / labels.size(0)}')\n",
    "    \n",
    "gt_labels = labels.numpy()\n",
    "confidences = prob.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5992bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels_copy = gt_labels.copy()\n",
    "confidences_copy = confidences.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee930ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_labels = gt_labels_copy.copy()\n",
    "confidences = confidences_copy.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e8a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'num non normalized confidence vectors = {np.sum((np.sum(confidences, axis=1) - 1) >= 1e-10)}')\n",
    "\n",
    "#confidences are not perfectly normalized due to floating point error\n",
    "#scipy.stats.dirichlet.pdf is very picky about normalization\n",
    "#convert confidences to float64 first for better/more accurate normalization\n",
    "\n",
    "confidences = np.array(confidences, dtype='float64')\n",
    "confidences = confidences / np.sum(confidences, axis=1)[:,None]\n",
    "print(f'num non normalized confidence vectors = {np.sum((np.sum(confidences, axis=1) - 1) >= 1e-10)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b77d1",
   "metadata": {},
   "source": [
    "# Fitting Fake Classifiers using MLE\n",
    "\n",
    "(Note: Any references to fitted results/distributions/graphs in the following sections used the LeNet5 as the 'real' neural network)\n",
    "\n",
    "Having gotten the confidences of our neural net on the CIFAR 10 test set we can now try and fit an appropiate fake classifier to them. This can be done quite easily for the Dirichlet and Multi-Dirichlet FC's using MLE, as we have relatively simple expressions for the distribution pdf's. The Multi-Gaussian FC is not as easy as the softmax function complicates the fake classifier's pdf. (It would be necessary to invert the softmax function, which is only possible up to an additive constant. As a result the Multi-Gaussian fake classifier's pdf will be an integral over a gaussian mixture model's pdf.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1499c9b",
   "metadata": {},
   "source": [
    "## 'Normal' MLE Fitting\n",
    "\n",
    "MLE is probably the easiest and simplest approach when the fake classifier's pdf is known exactly. We calculate the negative log likelihood of our neural net's confidence vector distribution under the assumption of either a Dirichlet or Multi-Dirichlet distribution. Using one of scipy's many minimization algorithms/functions we can find the set of parameters of the fake classifier that maximize the log-likelihood/minimize the negative log-likelihood.\n",
    "\n",
    "As always with fitting the choice of minimization algorithm, initial guesses and bounds is important:\n",
    "\n",
    "As discussed at the start a somewhat alright fake classifier can possibly be achieved by using a simple Dirichlet Fake Classifier with alpha parameters $\\alpha_n < 1$. For fitting the DirichletFC appropiate initial guesses and bounds might therefore be $\\vec{\\alpha}_\\text{init} = (1,1,1,1,...)$  and $\\alpha_\\min, \\alpha_\\max = (0.0001, \\text{None})$\n",
    "\n",
    "As dicussed at the start the reasoning behind the Multi-Dirichlet FC is that each separate Dirichlet can be used to create a local maximum in one of the corners of the simplex. This only works if the full alpha vector of each dirichlet has all entries $>1$ (if any entry is $<1$ a local maximum does not exist), which means for each Dirichlet wee need $\\alpha_k >1$ and $\\sigma_k>1$. We also expect the maxima to be very 'squished' into the corners. i.e. $\\alpha_k$ to be large. For fitting the Multi-Dirichlet FC appropate initial guesses and bounds might therefore be $\\vec{\\alpha}_{k,\\text{init}} = (10,10,10,10,...)$ $\\vec{\\sigma}_\\text{init} = (2,2,2,2,...)$ (squished into corners) and $\\alpha_{k,\\min}, \\alpha_{k,\\max} = (1, \\text{None})$ $\\sigma_\\min, \\sigma_\\max = (1, \\text{None})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4423350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the 'EvalStats' all the fitted FC's for easier comparison later\n",
    "#Very ugly but I didnt want to rename everything\n",
    "save_fc_eval = []\n",
    "save_NLL     = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ad43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Dirichlet FC to the test set confidence vector distributions using MLE fitting\n",
    "\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "Dir_FC = DirichletFC(num_classes)\n",
    "Dir_NLL = lambda parm: -np.sum(np.log( Dir_FC.pdf(confidences, parm) ))\n",
    "\n",
    "#initial guesses and bounds for fitting simple dirichlet\n",
    "init_alpha = 1*np.ones(num_classes)\n",
    "bounds_alpha = [(0.0001, None)] * num_classes\n",
    "\n",
    "Dirichlet_bestfit = scipy.optimize.minimize(Dir_NLL, init_alpha, bounds=bounds_alpha, options={'disp': True})\n",
    "save_NLL.append(Dirichlet_bestfit.fun)\n",
    "print(f'final NLL = {Dirichlet_bestfit.fun}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Multi-Dirichlet FC to the test set confidence vector distributions using MLE fitting\n",
    "\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "MultiDir_NLL = lambda parm: -np.sum(np.log( MultiDir_FC.pdf(confidences, *np.split(parm,3)) ))\n",
    "\n",
    "#initial guesses and bounds for fitting multi-dirichlet\n",
    "init_alpha = 10*np.ones(num_classes)\n",
    "init_sigma = 2*np.ones(num_classes)\n",
    "init_distribution_weights = np.ones(num_classes) / num_classes\n",
    "bounds_alpha = [(1, None)] * num_classes\n",
    "bounds_sigma = [(1, None)] * num_classes\n",
    "bounds_distribution_weights = [(0, 1)] * num_classes\n",
    "\n",
    "MultiDirichlet_bestfit = scipy.optimize.minimize(MultiDir_NLL,\n",
    "                                                 np.concatenate((init_alpha, init_sigma, init_distribution_weights)),\n",
    "                                                 bounds=bounds_alpha + bounds_sigma + bounds_distribution_weights,\n",
    "                                                 options={'disp': True})\n",
    "save_NLL.append(MultiDirichlet_bestfit.fun)\n",
    "print(f'final NLL = {MultiDirichlet_bestfit.fun}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc48f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Fitted FC parameters\n",
    "print(f'alpha = {Dirichlet_bestfit.x}\\n')\n",
    "print('alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}'.format(*np.split(MultiDirichlet_bestfit.x,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set FC parameters to those found from MLE fit\n",
    "Dir_FC.set_alpha(Dirichlet_bestfit.x)\n",
    "MultiDir_FC.set_parameters(*np.split(MultiDirichlet_bestfit.x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde0a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#visual comparison of neural network and FC distributions\n",
    "Dir_FC_eval = EvalStats(*Dir_FC.get_sample_arrays(50000))\n",
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "Dir_FC_eval.plot_confidence_distributions([0, \"top_class\"])\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    Dir_FC_eval.plot_confidence_distributions([i])\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8dd436",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(Dir_FC_eval)\n",
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad12c50",
   "metadata": {},
   "source": [
    "Above we have plotted the top class confidence distribution as well as the marginal confidence distributions for the actual neural network and our fitted fake classifiers (the full 10D confidence vector distribution is unfortuanetly a teeny bit difficult to visualise). This allows us to visually inspect how well our fake classifiers really reflect the true confidence distribution of our classifier. The 1st, 4th, ... graphs are the simple dirichlet FC. The 2nd, 5th, ... graphs are the multi-dirichlet FC. The 3rd, 6th, ... graphs are the real neural network confidence distributions.\n",
    "\n",
    "As expected the simple dirichlet FC does not work well. It doesn't capture the multimodal nature of the true marginal distribution nor the high frequency of p=1.0 confidences in the top class confidence distributions.\n",
    "\n",
    "The Multi-dirichlet FC seems to be a bit better capturing both of these qualities. However the maxima of the distributions don't lie far enough at the extremes, which is likely due to the fact that the local maximum of a dirichlet only lies exactly on the corner in the limit of $\\alpha_k \\rightarrow \\infty$\n",
    "\n",
    "Also of note is that the Multi-Dirichlet FC always tries to fit $\\sigma < 1$, always reaching the lower bound of $\\sigma = 1$ which we have imposed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c9cb54",
   "metadata": {},
   "source": [
    "## 'Sufficiently Confident/Class Split' MLE Fitting \n",
    "\n",
    "Given the slight difficulties with fitting a 30 parameter Multi-Dirichlet model we try to simplify the fitting a bit. This can be done by assuming a scenario very similar to that of sufficiently confident fake classifiers. We assume that if we draw a confidence vector from the k'th dirichlet distribution, then that confidence vector always predicts the class k. That means:\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\text{argmax}(\\vec{c}) = k | \\vec{c} \\sim \\text{Dir}_k) \\simeq 1 \\text{  or equivalently  } P(\\text{argmax}(\\vec{c}) = k) \\simeq p_k \n",
    "\\end{equation}\n",
    "\n",
    "where $p_k$ is the weight of the k'th dirichlet distribution. This is of course only a good approximation if $P(\\text{argmax}(\\vec{c}) \\neq k | \\vec{c} \\sim \\text{Dir}_k) \\simeq 0$, i.e. if the individual Dirichlet distributions are sufficiently concentrated in their respective corner of the simplex with only negligible probability mass near the other corners of the simplex.\n",
    "\n",
    "From the marginal class confidence distribution of the real neural network, we can see that this might be a very good approximation, as the class confidences always either lie near $c_k = 1.0$ or $c_k = 0.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d8482",
   "metadata": {},
   "source": [
    "This approximation makes two simplifications possible:\n",
    "\n",
    "1. We no longer have to fit the distribution weights $p_k$. Instead they can simply be read off from the real neural networks predicted class probabilities. This reduces the number of fitted parameters from 30 to 20\n",
    "\n",
    "2. We can now fit each Dirichlet distribution from the Multi-Dirichlet Fake classifier individually to the subset of the data for which $\\text{argmax}(\\vec{c}) = k$. This reduces the problem further from a simultaneous fit of 20 parameters to 10 fits of 2 parameters each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac25abe",
   "metadata": {},
   "source": [
    "We proceed in the following way: First we split the real neural networks confidence distribution by predicted class into 10 subsets. Using the relative size of these subest we estimate the distribution weights of the dirichlet distributions in our Multi-Dirichlet FC. We then fit each dirichlet distribution of our Multi-Dirichlet FC separately to its corresponding data set, by minimizing the negative log likelihood as before.\n",
    "\n",
    "Note that as we are now fitting each dirichlet distribution of the Multi-Dirichlet fake classifier individually we can no longer use MultiDirichletFC.pdf() directly, instead we have to use the pdf of a single dirichlet, DirichletFC.pdf(), with a parameter vector $\\sigma_k\\cdot[1, 1, ..., 1, \\alpha_k, 1, ...]$ for our NLL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b26cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the full confidence vector distribution of the real nn into subsets by predicted class\n",
    "num_classes = confidences.shape[1]\n",
    "class_split_confidences = [confidences[np.argmax(confidences, axis=1)==i, :] for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate Multi-Dirichlet distribution weights from the real neural networks predicted class distribution\n",
    "estimated_distribution_weights = [k_class_confidences.shape[0] for k_class_confidences in class_split_confidences]\n",
    "estimated_distribution_weights = estimated_distribution_weights / np.sum(estimated_distribution_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a76ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir_FC = DirichletFC(num_classes)\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "\n",
    "alpha_k = []\n",
    "sigma_k = []\n",
    "NLL_k   = []\n",
    "\n",
    "for k, k_class_confidences in enumerate(class_split_confidences):\n",
    "    \n",
    "    def k_dir_NLL(alpha, sigma):\n",
    "        alpha_vector = np.ones(num_classes)\n",
    "        alpha_vector[k] = alpha\n",
    "        alpha_vector *= sigma\n",
    "        return -np.sum(np.log( Dir_FC.pdf(k_class_confidences, alpha_vector) ))\n",
    "\n",
    "    #initial guesses and bounds for fitting individual dirichlets\n",
    "    init_alpha = 10\n",
    "    init_sigma = 2\n",
    "    bounds_alpha = [(1, None)]\n",
    "    bounds_sigma = [(1, None)]\n",
    "\n",
    "    k_dir_bestfit = scipy.optimize.minimize(lambda parms: k_dir_NLL(*parms), np.array([init_alpha, init_sigma]),\n",
    "                                            bounds = bounds_alpha + bounds_sigma,\n",
    "                                            options={'disp': True})\n",
    "    \n",
    "    alpha_k.append(k_dir_bestfit.x[0])\n",
    "    sigma_k.append(k_dir_bestfit.x[1])\n",
    "    NLL_k.append(k_dir_bestfit.fun)\n",
    "    \n",
    "save_NLL.append(np.sum(NLL_k))\n",
    "print(f'final NLL = {np.sum(NLL_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Multi-Dirichlet FC parameters to estimated distribution weights and fitted alpha_k and sigma_k values\n",
    "MultiDir_FC.set_parameters(alpha_k, sigma_k, estimated_distribution_weights)\n",
    "print('alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}'.format(*MultiDir_FC.get_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2c84a",
   "metadata": {},
   "source": [
    "Similar to above we can now visiually compare the marginal and top class confidence distributions of our fake classifier and the real neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53399344",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd8860",
   "metadata": {},
   "source": [
    "This doesn't really seem to work much better than fitting all 30 parameters at the same time (although it is definietly much faster in terms of computational time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654ff88",
   "metadata": {},
   "source": [
    "## Sigma < 1\n",
    "\n",
    "Interestingly enough it runs into the same problem of always trying to fit very small $\\sigma_k < 1$, even though the sensible/intuitve choice would be $\\sigma_k > 1$. This indicates that maybe our sensible/intuitve choice of wanting $\\sigma_k > 1$ isn't actually that sensible. As explained earlier the reasoning behind the Multi-Dirichlet model is that each Dirichlet distribution is used to create a local maximum in one of the corners of the simplex, with $\\alpha_k$ determining how squished into the corner and $\\sigma_k$ how broad the local maximum is. The requirement of $\\sigma_k > 1$ and $\\alpha_k > 1$ arose, because if any parameter of the Dirichlet is $< 1$ a local maximum does not exist and our whole reasoning behind introducing the Multi-Dirichlet fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c5050c",
   "metadata": {},
   "source": [
    "However, as it turns out a reasonable parameter choice might also be $\\sigma_k < 1$, with $\\alpha_k \\cdot \\sigma_k > 1$. This would mean that all parameters of the dirichlet, with exception of the k'th entry, are $ < 1$. While a local maximum no longer exists (we now have divergences at the sides and corners) this can still lead to an equivalent situation with most of the probability mass concentrated in one corner of the simplex. Below is a quick and dirty visualisation of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c360ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20,9))\n",
    "\n",
    "vis_dir_FC = DirichletFC(3)\n",
    "\n",
    "vis_dir_FC.set_alpha([0.2, 20, 0.2])\n",
    "_, vis_confidences = vis_dir_FC.get_sample_arrays(10000)\n",
    "\n",
    "ax[0].scatter(vis_confidences[:,0], vis_confidences[:,1], s=0.1)\n",
    "ax[0].plot([0,1], [1,0], 'r--')\n",
    "ax[0].plot([0,1], [0,0], 'r--')\n",
    "ax[0].plot([0,0], [0,1], 'r--')\n",
    "ax[0].set_xlim([-0.2,1.2])\n",
    "ax[0].set_ylim([-0.2,1.2])\n",
    "\n",
    "vis_dir_FC.set_alpha([2, 50, 2])\n",
    "_, vis_confidences = vis_dir_FC.get_sample_arrays(10000)\n",
    "\n",
    "ax[1].scatter(vis_confidences[:,0], vis_confidences[:,1], s=0.1)\n",
    "ax[1].plot([0,1], [1,0], 'r--')\n",
    "ax[1].plot([0,1], [0,0], 'r--')\n",
    "ax[1].plot([0,0], [0,1], 'r--')\n",
    "ax[1].set_xlim([-0.2,1.2])\n",
    "ax[1].set_ylim([-0.2,1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176821eb",
   "metadata": {},
   "source": [
    "Below we have repeated both the direct Multi-Dirichlet FC fitting as well as the 'class split' fitting, but this time with a lower bound for sigma of $\\sigma_\\text{lower} = 0.001$. Allowing for this seems to improve things a bit, but it is still a far cry from properly resembling the true marginal and top class confidence distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc780ad4",
   "metadata": {},
   "source": [
    "### First the simultaneous fit of 30 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99df3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Multi-Dirichlet FC to the test set confidence vector distributions using MLE fitting\n",
    "\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "MultiDir_NLL = lambda parm: -np.sum(np.log( MultiDir_FC.pdf(confidences, *np.split(parm,3)) ))\n",
    "\n",
    "#initial guesses and bounds for fitting multi-dirichlet\n",
    "init_alpha = 10*np.ones(num_classes)\n",
    "init_sigma = 2*np.ones(num_classes)\n",
    "init_distribution_weights = np.ones(num_classes) / num_classes\n",
    "bounds_alpha = [(1, None)] * num_classes\n",
    "bounds_sigma = [(0.001, None)] * num_classes\n",
    "bounds_distribution_weights = [(0, 1)] * num_classes\n",
    "\n",
    "MultiDirichlet_bestfit = scipy.optimize.minimize(MultiDir_NLL,\n",
    "                                                 np.concatenate((init_alpha, init_sigma, init_distribution_weights)),\n",
    "                                                 bounds=bounds_alpha + bounds_sigma + bounds_distribution_weights,\n",
    "                                                 options={'disp': True})\n",
    "\n",
    "save_NLL.append(MultiDirichlet_bestfit.fun)\n",
    "print(f'final NLL = {MultiDirichlet_bestfit.fun}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab6efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set FC parameters to those found from MLE fit\n",
    "MultiDir_FC.set_parameters(*np.split(MultiDirichlet_bestfit.x,3))\n",
    "print('alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}'.format(*np.split(MultiDirichlet_bestfit.x,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual comparison of neural network and FC distributions\n",
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57486d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0172f1",
   "metadata": {},
   "source": [
    "### And secondly the 10 fits of 2 parameters each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the full confidence vector distribution of the real nn into subsets by predicted class\n",
    "num_classes = confidences.shape[1]\n",
    "class_split_confidences = [confidences[np.argmax(confidences, axis=1)==i, :] for i in range(num_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate Multi-Dirichlet distribution weights from the real neural networks predicted class distribution\n",
    "estimated_distribution_weights = [k_class_confidences.shape[0] for k_class_confidences in class_split_confidences]\n",
    "estimated_distribution_weights = estimated_distribution_weights / np.sum(estimated_distribution_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee5dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir_FC = DirichletFC(num_classes)\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "\n",
    "alpha_k = []\n",
    "sigma_k = []\n",
    "NLL_k   = []\n",
    "\n",
    "for k, k_class_confidences in enumerate(class_split_confidences):\n",
    "    \n",
    "    def k_dir_NLL(alpha, sigma):\n",
    "        alpha_vector = np.ones(num_classes)\n",
    "        alpha_vector[k] = alpha\n",
    "        alpha_vector *= sigma\n",
    "        return -np.sum(np.log( Dir_FC.pdf(k_class_confidences, alpha_vector) ))\n",
    "\n",
    "    #initial guesses and bounds for fitting individual dirichlets\n",
    "    init_alpha = 10\n",
    "    init_sigma = 2\n",
    "    bounds_alpha = [(1, None)]\n",
    "    bounds_sigma = [(0.001, None)]\n",
    "\n",
    "    k_dir_bestfit = scipy.optimize.minimize(lambda parms: k_dir_NLL(*parms), np.array([init_alpha, init_sigma]),\n",
    "                                            bounds = bounds_alpha + bounds_sigma,\n",
    "                                            options={'disp': True})\n",
    "    \n",
    "    alpha_k.append(k_dir_bestfit.x[0])\n",
    "    sigma_k.append(k_dir_bestfit.x[1])\n",
    "    NLL_k.append(k_dir_bestfit.fun)\n",
    "    \n",
    "save_NLL.append(np.sum(NLL_k))\n",
    "print(f'final NLL = {np.sum(NLL_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set Multi-Dirichlet FC parameters to estimated distribution weights and fitted alpha_k and sigma_k values\n",
    "MultiDir_FC.set_parameters(alpha_k, sigma_k, estimated_distribution_weights)\n",
    "print('alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}'.format(*MultiDir_FC.get_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e783d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b49390",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076089c",
   "metadata": {},
   "source": [
    "## Further Modifications to Fitting Procedure\n",
    "\n",
    "Other 'improvements' that can be made is to modify the fitting in two ways:\n",
    "\n",
    "1. Scale/Transform the confidences that we are trying to fit\n",
    "\n",
    "2. Scale/Transform the parameters we are trying to fit\n",
    "\n",
    "See https://epub.wu.ac.at/4077/1/Report125.pdf for more info on fitting dirichlets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373eacf",
   "metadata": {},
   "source": [
    "1:\n",
    "\n",
    "An important problem that we haven't quite adressed/just ignored are divergences in the distribution and the log-likelihood. First of all an 'obvious' divergence occurs if any of the dirichlet parameters are $< 1$. For such a case the pdf on the sides/corners of the simplex corresponding to this parameter will have a divergence $\\text{pdf} \\rightarrow \\infty$. As a result the log-likelihood will also diverge. Slightly less obvious however is that this divergence still occurs if the parameters of the dirichlet are $> 1$. In this case the pdf on the sides/corners of the simplex will be $= 0$, which also leads to a divergence in the log-lieklihood which we are trying to fit.\n",
    "\n",
    "In short if any component of the confidence vector $= 0$ we run into divergences (and the confidence distribution of our real neural networks have a lot of $0$ confidence values)\n",
    "\n",
    "To mitigate this we can rescale the confidences before fitting according to\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{c} = \\frac{\\vec{c}(N-1) + 1/\\text{num_classes}}{N}\n",
    "\\end{equation}\n",
    "\n",
    "where N is the number of samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec894ea",
   "metadata": {},
   "source": [
    "2:\n",
    "\n",
    "In general, introducing bounds into minimzation problems can complicate things. However instead of fitting the dirichlet parameters directly we can first rescale/transform them onto the interval $[-\\infty, \\infty]$ (Very similar to the idea of generalized linear models, just that we do not have predictor variables in our case).\n",
    "\n",
    "For the simple dirichlet FC and appropiate rescaling would be $log(\\cdot)$ mapping the allowed alpha interval $[0, \\infty]$ onto $[-\\infty, \\infty]$\n",
    "\n",
    "For the multi-dirichlet FC, with $\\sigma > 0$ and $\\alpha > 1$ an appropiate transform would be e.g. $log(\\sigma)$ and $log(\\alpha - 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b629f308",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "As it turns out rescaling values might not be that great of an idea. The problem is that the minimization algorithms end up taking stepsizes of up to $10$ in $\\log(\\alpha)$ which results in $\\alpha \\sim 10^{10}$. Even after rescaling the confidences to avoid 0 values, we still run into problems with such a large alpha. For a value of $c \\sim 10^{-5}$, we get $c^\\alpha \\sim 10^{-50}$ which might as well be 0 and will lead to errors in the log-likelihood. Although this doesn't actually seem to affect results too much, it still finds the same minimum as a minimization without log transforms but with bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416f7fe",
   "metadata": {},
   "source": [
    "Let's try fitting the Multi-Dirichlet FC again in both ways, all 30 parameters directly and 10 times 2 parameters, while applying the two imporvements mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale the confidences to avoid 0 confidences and renormalize\n",
    "\n",
    "num_classes = confidences.shape[1]\n",
    "\n",
    "rescaled_confidences = (confidences * (confidences.shape[0] - 1) + 1/num_classes) / confidences.shape[0]\n",
    "rescaled_confidences = rescaled_confidences / np.sum(rescaled_confidences, axis=1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afdb89c",
   "metadata": {},
   "source": [
    "### First the simultaneous fit of 30 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfba92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "\n",
    "def MultiDir_NLL(log_alpha, log_sigma, logit_distribution_weights):\n",
    "    alpha = np.exp(log_alpha)+1\n",
    "    sigma = np.exp(log_sigma)\n",
    "    distribution_weights = np.exp(logit_distribution_weights) / (1 + np.exp(logit_distribution_weights))\n",
    "    return -np.sum(np.log( MultiDir_FC.pdf(rescaled_confidences, alpha, sigma, distribution_weights) ))\n",
    "    \n",
    "#initial guesses for fitting multi-dirichlet (no longer need bounds due to log transformations)\n",
    "init_log_alpha = np.zeros(num_classes)\n",
    "init_log_sigma = np.zeros(num_classes)\n",
    "init_logit_distribution_weights = np.zeros(num_classes)\n",
    "\n",
    "MultiDirichlet_bestfit = scipy.optimize.minimize(lambda parms: MultiDir_NLL(*np.split(parms,3)),\n",
    "                                                 np.concatenate((init_log_alpha, init_log_sigma, init_logit_distribution_weights)),\n",
    "                                                 options={'disp': True})\n",
    "save_NLL.append(MultiDirichlet_bestfit.fun)\n",
    "print(f'final NLL = {MultiDirichlet_bestfit.fun}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set FC parameters to those found from MLE fit\n",
    "l_a, l_s, l_w = np.split(MultiDirichlet_bestfit.x,3)\n",
    "MultiDir_FC.set_parameters(np.exp(l_a)+1, np.exp(l_s), np.exp(l_w) / (1 + np.exp(l_w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ef2bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}'.format(*np.split(MultiDirichlet_bestfit.x,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4878ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c4a3e1",
   "metadata": {},
   "source": [
    "### And secondly the 10 fits of 2 parameters each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d405235",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_split_confidences = [rescaled_confidences[np.argmax(rescaled_confidences, axis=1)==i, :] for i in range(num_classes)]\n",
    "\n",
    "estimated_distribution_weights = [k_class_confidences.shape[0] for k_class_confidences in class_split_confidences]\n",
    "estimated_distribution_weights = estimated_distribution_weights / np.sum(estimated_distribution_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad35460",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir_FC = DirichletFC(num_classes)\n",
    "MultiDir_FC = MultiDirichletFC(num_classes)\n",
    "\n",
    "alpha_k = []\n",
    "sigma_k = []\n",
    "NLL_k\n",
    "\n",
    "for k, k_class_confidences in enumerate(class_split_confidences):\n",
    "    \n",
    "    def k_dir_NLL(log_alpha, log_sigma):\n",
    "        alpha_vector = np.ones(num_classes)\n",
    "        alpha_vector[k] = np.exp(log_alpha)+1 \n",
    "        alpha_vector *= np.exp(log_sigma)\n",
    "        return -np.sum(np.log( Dir_FC.pdf(k_class_confidences, alpha_vector) ))\n",
    "\n",
    "    #initial guesses fitting individual dirichlets (no longer need bounds due to log transformations)\n",
    "    init_log_alpha = 0\n",
    "    init_log_sigma = 0\n",
    "\n",
    "    k_dir_bestfit = scipy.optimize.minimize(lambda parms: k_dir_NLL(*parms), np.array([init_log_alpha, init_log_sigma]),\n",
    "                                            options={'disp': True})\n",
    "    \n",
    "    alpha_k.append(np.exp(k_dir_bestfit.x[0])+1)\n",
    "    sigma_k.append(np.exp(k_dir_bestfit.x[1]))\n",
    "    NLL_k.append(k_dir_bestfit.fun)\n",
    "\n",
    "save_NLL.append(np.sum(NLL_k))\n",
    "print(f'final NLL = {np.sum(NLL_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bbee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC.set_parameters(alpha_k, sigma_k, estimated_distribution_weights)\n",
    "print('alpha_k = {}\\n\\nsigma_k = {}\\n\\ndistribution_weights = {}'.format(*MultiDir_FC.get_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiDir_FC_eval = EvalStats(*MultiDir_FC.get_sample_arrays(50000))\n",
    "NNet_eval = EvalStats(gt_labels, confidences)\n",
    "\n",
    "MultiDir_FC_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "NNet_eval.plot_confidence_distributions([0,\"top_class\"])\n",
    "\n",
    "for i in range(3):\n",
    "    MultiDir_FC_eval.plot_confidence_distributions([i])\n",
    "    NNet_eval.plot_confidence_distributions([i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8344d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fc_eval.append(MultiDir_FC_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713b7fe7",
   "metadata": {},
   "source": [
    "For easier comparison the results are aggregated here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2674d5a",
   "metadata": {},
   "source": [
    "### Real NN's Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c824e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "NNet_eval.plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "NNet_eval.plot_confidence_distributions([0], new_fig = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c88e7c",
   "metadata": {},
   "source": [
    "### Dirichlet FC Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fec3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[0]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[0].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[0].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2c2ec",
   "metadata": {},
   "source": [
    "### Directly Fitted Multi Dirichlet FC Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b58dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[1]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[1].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[1].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2776ab",
   "metadata": {},
   "source": [
    "### Class Split Fitted Multi Dirichlet FC Confidence Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[2]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[2].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[2].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d6c0f",
   "metadata": {},
   "source": [
    "### Directly Fitted Multi Dirichlet FC Confidence Distribution, sigma < 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[3]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[3].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[3].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728487c5",
   "metadata": {},
   "source": [
    "### Class Split Fitted Multi Dirichlet FC Confidence Distribution, sigma < 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[4]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[4].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[4].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08654d6e",
   "metadata": {},
   "source": [
    "### 'Improved' Directly Fitted Multi Dirichlet FC Confidence Distribution, sigma < 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabe8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[5]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[5].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[5].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0438181",
   "metadata": {},
   "source": [
    "### 'Improved' Class Split Fitted Multi Dirichlet FC Confidence Distribution, sigma < 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'final NLL = {save_NLL[6]}')\n",
    "fig, axs = plt.subplots(1,2, figsize=(18,7))\n",
    "plt.axes(axs[0])\n",
    "save_fc_eval[6].plot_confidence_distributions([\"top_class\"], new_fig = False)\n",
    "plt.axes(axs[1])\n",
    "save_fc_eval[6].plot_confidence_distributions([0], new_fig = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a665cc1",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Comparing how well different models fit is always a bit of a tricky thing to do. The Likelihood ratio test only works for comparing nested models, i.e. models where one is a special/restricted case of the other model, which is unfortunately not the case here.\n",
    "\n",
    "However, non-nested models can be compared (informally) using the Akaike Information Criterion (AIC) defines as:\n",
    "\n",
    "\\begin{equation}\n",
    "AIC = 2k - 2\\ln(\\hat{L})\n",
    "\\end{equation}\n",
    "\n",
    "where $k$ is the number of parameters of the model and $\\hat{L}$ the maximum lilelihood.\n",
    "\n",
    "Given that our models have parameters of either on the order of $\\sim 10^1$ whereas $\\ln(\\hat{L}) \\sim 10^6$ we can pretty much just compare likelihoods directly.\n",
    "\n",
    "### For the LeNet 5 we conclude:\n",
    "\n",
    "1. Suprisingly, the simple Dirichlet fits the real NN better than the Multi-Dirichlet with $\\sigma > 1$, even though visually it looks like the Multi-Dirichlet captures/reproduces the marginal distributions of the real NN a lot better\n",
    "\n",
    "2. Also suprisingly, fitting the Multi-Dirichlet directly gives worse results according to the AIC comared to fitting it via the approximation of 'class splitting' (even though, again, the directly fitted Multi-Dirichlet marginal distributions looks more 'real')\n",
    "\n",
    "3. Allowing for $\\sigma < 1$ improves the AIC a lot for both directly and class split fitted Multi-Dirichlet FC's\n",
    "\n",
    "4. The 'Improvements' to the fitting, transforming data and parameters, seem to have varying effects: They improve class split fitting but make direct fitting worse and in general the log transforms seem to introduce more warnings and complications to the fitting than they get rid of.\n",
    "\n",
    "The most promising results seem to therefore be achieved using the directly fitted Multi-Dirichlet FC with sigma < 1. While it does actually result in a slightly worse AIC than the same class-split FC the marginal distributions look a lot more 'real'.\n",
    "\n",
    "### For the ResNet 20 we conclude:\n",
    "\n",
    "Similar results as for the LeNet 5 with one major exception:\n",
    "\n",
    "The difference between the class split and directly fitted multi dirichlet FC is negligibly small. This not a suprise as we expect the more complex NN's to be more confident in general, i.e. for the confidences to be more concentrated in the corners. This makes the more complex NN's closer to a 'sufficiently confident like' behaviour that we based the class split fitting approximation on.\n",
    "\n",
    "Again the most promising results seem to be achieved using the directly fitted Multi-Dirichlet FC with sigma < 1.\n",
    "\n",
    "### For the ResNet 110 we conclude:\n",
    "\n",
    "Pretty much almost the same as for the ResNet 20\n",
    "\n",
    "### In General:\n",
    "\n",
    "The Multi-Dirichlet FC seems to be a lot better at reproducing the ResNet 20 and ResNet 110 confidence distributions. The LeNet 5 is more difficult for the Multi-Dirichlet FC to reproduce. This is likely due to the LeNet 5 not being 'overconfident enough', i.e. when looking at  the LeNet's 'top class' confidence distribution a fair amount of confidences lie in the middle of the distribution at $p \\sim 0.5$. For ResNet 20 and ResNet 110 this is not the case, pretty much all confidences lie at the extreme value of $p \\sim 1.0$.\n",
    "\n",
    "The transform of the confidences to avoid 0 confidences is probably a good thing to keep.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207568b4",
   "metadata": {},
   "source": [
    "Maybe TODO: Try other fitting methods: e.g. moment matching or fitting only to the marginal distributions\n",
    "\n",
    "Maybe TODO: Try 'stochastic fitting' for the multi-gaussian FC where we sample the FC calculate the corrseponding marginal distributions and minimize e.g. the squared error loss between the neural network marginal distributions and the marginal distributions sampled from the FC. Could get around problem of multi-gaussian FC having analytically intractable pdf\n",
    "\n",
    "TODO: Find a good simplex automorphism to also recreate the reliability diagrams of the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd7a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
