{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Note - this cell should be executed only once per session\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# in order to get the config, it is not part of the library\n",
    "\n",
    "if os.path.basename(os.getcwd()) != \"notebooks\":\n",
    "    raise Exception(f\"Wrong directory. Did you execute this cell twice?\")\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.path.abspath(\".\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from kyle.calibration.calibration_methods import TemperatureScaling, ClassWiseCalibration, \\\n",
    "    ConfidenceReducedCalibration, BetaCalibration, BaseCalibrationMethod, IsotonicRegression\n",
    "from kyle.evaluation import EvalStats\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading Models and Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "\n",
    "dataset = make_classification(n_samples=60000, n_classes=n_classes, n_informative=15)\n",
    "\n",
    "X, y = dataset\n",
    "# X, y = dataset[\"data\"], dataset[\"target\"]\n",
    "\n",
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_size = 0.5\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n",
    "\n",
    "train_index, test_index = list(sss.split(X, y))[0]\n",
    "X_train, y_train = X[train_index], y[train_index]\n",
    "X_test, y_test = X[test_index], y[test_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "confidences = model.predict_proba(X_test)\n",
    "y_pred = confidences.argmax(1)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading model and data\n",
    "\n",
    "confidences = confidences\n",
    "gt_labels = y_test\n",
    "\n",
    "\n",
    "## Visualizing Distribution of Confidences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap(\"tab10\")\n",
    "bins = 50\n",
    "\n",
    "fig, axes = plt.subplots(n_classes, figsize=(5, 5))\n",
    "fig.suptitle(\"Distribution of confidences in predicted classes\", fontsize=14)\n",
    "for count, row in enumerate(axes):\n",
    "    row.set_title(f\"Predicted Class {count}\")\n",
    "    color_left, color_right = cmap(count), cmap(count + 5)\n",
    "    max_confs = confidences[confidences.argmax(1) == count].max(1)\n",
    "    row.hist(max_confs, density=True, color=color_left, bins=bins)\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Temperature Scaling in Normal, Reduced adn Class-wise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simple Evaluation with Train/Validation Split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_size = 0.5\n",
    "bins = 20 # for ECE\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n",
    "train_index, test_index = list(sss.split(confidences, gt_labels))[0]\n",
    "confidences_train, gt_labels_train = confidences[train_index], gt_labels[train_index]\n",
    "confidences_test, gt_labels_test = confidences[test_index], gt_labels[test_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the initial reliability curve and ECE of the resnet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uncalibrated_eval_stats = EvalStats(gt_labels_test, confidences_test, bins=bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"ECE uncalibrated: {uncalibrated_eval_stats.expected_calibration_error()}\")\n",
    "print(f\"Marginal uncalibrated: {uncalibrated_eval_stats.expected_marginal_calibration_error(1)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "uncalibrated_eval_stats.plot_reliability_curves([EvalStats.TOP_CLASS_LABEL], display_weights=True)\n",
    "plt.title(\"Uncalibrated reliabilities\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reduced Temp Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_scaling_full = TemperatureScaling()\n",
    "t_scaling_binary = ConfidenceReducedCalibration()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_scaling_full.fit(confidences_train, gt_labels_train)\n",
    "t_scaling_binary.fit(confidences_train, gt_labels_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recalibrated_full_confs = t_scaling_full.get_calibrated_confidences(confidences_test)\n",
    "recalibrated_reduced_confs = t_scaling_binary.get_calibrated_confidences(confidences_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recalibrated_full_eval_stats = EvalStats(gt_labels_test, recalibrated_full_confs, bins=bins)\n",
    "recalibrated_binary_eval_stats = EvalStats(gt_labels_test, recalibrated_reduced_confs, bins=bins)\n",
    "\n",
    "print(f\"Temp Scaling ECE: {recalibrated_full_eval_stats.expected_calibration_error()}\")\n",
    "print(f\"Reduced Temp Scaling ECE: {recalibrated_binary_eval_stats.expected_calibration_error()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recalibrated_full_eval_stats.plot_reliability_curves([EvalStats.TOP_CLASS_LABEL], display_weights=True)\n",
    "plt.title(\"Temp scaling\")\n",
    "plt.show()\n",
    "\n",
    "recalibrated_binary_eval_stats.plot_reliability_curves([EvalStats.TOP_CLASS_LABEL], display_weights=True)\n",
    "plt.title(\"Reduced temp scaling\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class-wise Temp Scaling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "classwise_scaler = ClassWiseCalibration()\n",
    "classwise_scaler.fit(confidences_train, gt_labels_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classwise_recalibrated_confs = classwise_scaler.get_calibrated_confidences(confidences_test)\n",
    "classwise_eval_stats = EvalStats(gt_labels_test, classwise_recalibrated_confs, bins=bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classwise_eval_stats.plot_reliability_curves([EvalStats.TOP_CLASS_LABEL], display_weights=True)\n",
    "plt.title(\"Class-wise Calibrated\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Class-wise Temp Scaling ECE: {classwise_eval_stats.expected_calibration_error()}\")\n",
    "print(f\"Temp Scaling ECE: {recalibrated_full_eval_stats.expected_calibration_error()}\")\n",
    "\n",
    "print(f\"Class-wise Temp Scaling cwECE: {classwise_eval_stats.class_wise_expected_calibration_error()}\")\n",
    "print(f\"Temp Scaling cwECE: {recalibrated_full_eval_stats.class_wise_expected_calibration_error()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp = TemperatureScaling()\n",
    "beta = BetaCalibration()\n",
    "classwise_temt = ClassWiseCalibration()\n",
    "classwise_beta = ClassWiseCalibration(BetaCalibration)\n",
    "classwise_reduced_temp = ConfidenceReducedCalibration(ClassWiseCalibration())\n",
    "reduced_temp = ConfidenceReducedCalibration()\n",
    "reduced_beta = ConfidenceReducedCalibration(BetaCalibration())\n",
    "isotonic = IsotonicRegression()\n",
    "reduced_isotonic = ConfidenceReducedCalibration(IsotonicRegression())\n",
    "\n",
    "classwise_reduced_isotonic = ClassWiseCalibration(lambda: ConfidenceReducedCalibration(IsotonicRegression()))\n",
    "\n",
    "def compute_score(scaler, confs: np.ndarray, labels: np.ndarray, bins, metric=\"ECE\"):\n",
    "    calibrated_confs = scaler.get_calibrated_confidences(confs)\n",
    "    eval_stats = EvalStats(labels, calibrated_confs, bins=bins)\n",
    "    if metric == \"ECE\":\n",
    "        return eval_stats.expected_calibration_error()\n",
    "    elif metric == \"cwECE\":\n",
    "        return eval_stats.class_wise_expected_calibration_error()\n",
    "    elif isinstance(metric, int):\n",
    "        return eval_stats.expected_marginal_calibration_error(metric)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric {metric}\")\n",
    "\n",
    "\n",
    "class Identity(BaseCalibrationMethod):\n",
    "    def fit(self, *args):\n",
    "        pass\n",
    "\n",
    "    def get_calibrated_confidences(self, confidences: np.ndarray):\n",
    "        return confidences\n",
    "\n",
    "def get_scores(scaler, metric, cv, bins):\n",
    "    scoring = lambda *args: compute_score(*args, bins=bins, metric=metric)\n",
    "    return cross_val_score(scaler, confidences, gt_labels, scoring=scoring, cv=cv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# get rid of the output produced by netcal. They use print instead of logging, it seems\n",
    "\n",
    "cv = 6\n",
    "bins = 20\n",
    "\n",
    "# bring in some randomness to the evaluations\n",
    "permutation = np.random.permutation(len(confidences))\n",
    "confidences = confidences[permutation]\n",
    "gt_labels = gt_labels[permutation]\n",
    "\n",
    "\n",
    "uncalibrated_ECE = get_scores(Identity(), \"ECE\", cv, bins)\n",
    "temp_ECE = get_scores(temp,  \"ECE\", cv, bins)\n",
    "beta_ECE = get_scores(beta, \"ECE\", cv, bins)\n",
    "\n",
    "cw_temp_ECE = get_scores(classwise_temt, \"ECE\", cv, bins)\n",
    "cw_beta_ECE = get_scores(classwise_beta, \"ECE\", cv, bins)\n",
    "reduced_temp_ECE = get_scores(reduced_temp, \"ECE\", cv, bins)\n",
    "# reduced_beta = get_scores(reduced_beta, \"ECE\", cv, bins)\n",
    "\n",
    "isotonic_ECE = get_scores(isotonic, \"ECE\", cv, bins)\n",
    "reduced_isotonic_ECE = get_scores(reduced_isotonic, \"ECE\", cv, bins)\n",
    "cw_reduced_isotonic_ECE = get_scores(classwise_reduced_isotonic, \"ECE\", cv, bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = [\n",
    "    # uncalibrated_ECE,\n",
    "    temp_ECE,\n",
    "    cw_temp_ECE,\n",
    "    # reduced_temp_ECE,\n",
    "    beta_ECE,\n",
    "    cw_beta_ECE,\n",
    "    # reduced_beta,\n",
    "    isotonic_ECE,\n",
    "    reduced_isotonic_ECE,\n",
    "    cw_reduced_isotonic_ECE,\n",
    "]\n",
    "labels = [\n",
    "    # \"Baseline 0 - ECE, uncalibrated\",\n",
    "    \"Baseline 1 - ECE, temperature\",\n",
    "    \"ECE, Class-wise temperature\",\n",
    "    # \"ECE, Reduced temperature\",\n",
    "    \"Baseline 2 - ECE, beta\",\n",
    "    \"ECE, Class-wise beta\",\n",
    "    # \"ECE, Reduced beta\",\n",
    "    \"Baseline 3 - ECE, Isotonic Regression\",\n",
    "    \"ECE, Reduced isotonic regression\",\n",
    "    \"ECE, CW-Reduced isotonic regression\"\n",
    "]\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.title(f\"CV with {cv} folds on {len(confidences)} data points. \\n\"\n",
    "          f\"ECE Scores computed with {bins} bins\")\n",
    "plt.boxplot(scores, labels=labels)\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "cv_class_wise = 6\n",
    "bins_class_wise = 20\n",
    "\n",
    "compute_cwECE = lambda *args: compute_score(*args, metric=\"cwECE\", bins=bins_class_wise)\n",
    "\n",
    "uncalibrated_cwECE = get_scores(Identity(), \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "temp_cwECE = get_scores(temp, \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "beta_cwECE = get_scores(beta, \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "\n",
    "cw_temp_cwECE = get_scores(classwise_temt, \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "cw_beta_cwECE = get_scores(classwise_beta, \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "\n",
    "isotonic_cwECE = get_scores(isotonic, \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "reduced_isotonic_cwECE = get_scores(reduced_isotonic, \"cwECE\", cv_class_wise, bins_class_wise)\n",
    "cw_reduced_isotonic_cwECE = get_scores(classwise_reduced_isotonic, \"cwECE\", cv_class_wise, bins_class_wise)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_cwECE = [\n",
    "    # uncalibrated_cwECE,\n",
    "    temp_cwECE,\n",
    "    cw_temp_cwECE,\n",
    "    beta_cwECE,\n",
    "    cw_beta_cwECE,\n",
    "    isotonic_cwECE,\n",
    "    reduced_isotonic_cwECE,\n",
    "    cw_reduced_isotonic_cwECE,\n",
    "]\n",
    "labels_cwECE = [\n",
    "    # \"Baseline 0 - cwECE, uncalibrated\",\n",
    "    \"Baseline 1 - cwECE, temperature\",\n",
    "    \"cwECE, Class-wise temperature\",\n",
    "    \"Baseline 2 - cwECE, beta\",\n",
    "    \"cwECE, Class-wise beta\",\n",
    "    \"Baseline 3 - cwECE, Isotonic Regression\",\n",
    "    \"cwECE, Reduced Isotonic Regression\",\n",
    "    \"cwECE, Class-wise reduced Isotonic Regression\",\n",
    "\n",
    "]\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.title(f\"CV with {cv_class_wise} folds on {len(confidences)} data points. \\n\"\n",
    "          f\"Class-wise ECE scores computed with {bins_class_wise} bins\")\n",
    "plt.boxplot(scores_cwECE, labels=labels_cwECE)\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "cv_marginal = 6\n",
    "class_for_marginal_error = 2\n",
    "marginal_bins = 20\n",
    "compute_score_marginal = lambda *args: compute_score(*args, metric=class_for_marginal_error, bins=marginal_bins)\n",
    "\n",
    "\n",
    "uncalibrated_cwECE_marginal = get_scores(Identity(), class_for_marginal_error, cv_marginal, marginal_bins)\n",
    "temp_cwECE_marginal = get_scores(temp, class_for_marginal_error, cv_marginal, marginal_bins)\n",
    "beta_cwECE_marginal = get_scores(beta, class_for_marginal_error, cv_marginal, marginal_bins)\n",
    "cw_temp_cwECE_marginal = get_scores(classwise_temt, class_for_marginal_error, cv_marginal, marginal_bins)\n",
    "cw_beta_cwECE_marginal = get_scores(classwise_beta, class_for_marginal_error, cv_marginal, marginal_bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "marginal_labels = [\n",
    "    # \"Baseline 0 - Marginal, uncalibrated\",\n",
    "    \"Baseline 1 - Marginal, temperature\",\n",
    "    \"Marginal, Class-wise temperature\",\n",
    "    \"Baseline 2 - Marginal, beta\",\n",
    "    \"Marginal, Class-wise beta\",\n",
    "]\n",
    "\n",
    "marginal_scores = [\n",
    "    # uncalibrated_cwECE_marginal,\n",
    "    temp_cwECE_marginal,\n",
    "    cw_temp_cwECE_marginal,\n",
    "    beta_cwECE_marginal,\n",
    "    cw_beta_cwECE_marginal\n",
    "]\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.title(f\"CV with {cv_marginal} folds on {len(confidences)} data points. \\n\"\n",
    "          f\"Marginal scores for class {class_for_marginal_error}. Computed with {marginal_bins} bins\")\n",
    "plt.boxplot(marginal_scores, labels=marginal_labels)\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}